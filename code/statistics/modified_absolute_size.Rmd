---
title: "Absolute_size"
output: html_document
date: '2022-07-04'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r import libraries, message=FALSE, warning=FALSE, }
library(tidyverse)
library(knitr)
library(openxlsx)
library(stats)
library(rlist)
library(plyr)
library(ggplot2)
library(dplyr)
```

## Compute Mann-Whitney Test

```{r}
get_u_stats <- function(table, shuffle=FALSE){
  n = 0
  U_x = 0
  U_y = 0
  langs = unique(table$language)
  for (lang in langs){
    
    lang_table <- table[table$language == lang,]
    lang_table <- lang_table[!is.na(lang_table$language),]
    
    lang_table$rank <- rank(lang_table$score)
    if (shuffle == TRUE){
      shuffled_lang_table <- transform(lang_table, rank=sample(rank))
      shuffled_lang_table %>% filter(gender=="3") -> gender_3
      shuffled_lang_table %>% filter(gender=="4") -> gender_4}
    else {
      lang_table %>% filter(gender=="3") -> gender_3
      lang_table %>% filter(gender=="4") -> gender_4
    }
  

    X <- gender_3$rank
    Y <- gender_4$rank
  
    n_x <- length(X)
    n_y <- length(Y)
    R_x <- sum(X)
    R_y <- sum(Y)
    u_x = n_x * n_y + (n_x * (n_x +1))/2 - R_x
    u_y = n_x * n_y + (n_y * (n_y +1))/2 - R_y
    U_x <- U_x + u_x
    U_y <- U_y + u_y
  }
  #u_observed = min(c(U_x, U_y))
  u_observed = U_x
  n = U_x + U_y
  output = c(u_observed, n)
  return (output)
  }
```

```{r}
grouped_mann_whitney <- function(table, name, iter) {
    output <- get_u_stats(table)
    u_observed <- output[1]
    n <- output[2]
    U_list <- list()
    num = 0
    for (i in 1:iter){
      output <- get_u_stats(table, TRUE)
      u <- output[1]
      if (u >= u_observed){
        num = num + 1
      }
      U_list <- list.append(U_list, 1-u/n)
    }
   # Us <- sort(Us, decreasing = FALSE)
    U_list <- lapply(U_list,sort,decreasing=TRUE)
    df <- ldply (U_list, data.frame)
    colnames(df) <- c("number")
    p <- ggplot(df, aes(x=number)) + geom_density() + geom_vline(aes(xintercept=1-u_observed/n), color="blue", linetype="dashed", linewidth=1) + xlab("Proportion of pairs 3 > 4")
    ggsave(p, 
       filename = sprintf("%s.pdf", name),
       device = "pdf",
       height = 6, width = 5, units = "in")
    return (num/length(U_list))
}
```

``` {r}
count_mw <- function(table, data, name, iter){
  table <- table[c("gender", "language", data)]
  colnames(table)[3] ="score"
  table <- table[!is.na(table$score),]
  
  test <- grouped_mann_whitney(table, sprintf("%s_%s", data, name), iter)
  return(1-test)
}
``` 


## Run code for each language

```{r  input: LIST OF NOUNS (for a given language)}

get_data <- function(words, big_concepts, small_concepts, name, iter, filter_animal=FALSE){
  
  if (filter_animal == TRUE){
    big_concepts %>% filter(is.na(animal)) -> big_concepts
    small_concepts %>% filter(is.na(animal)) -> small_concepts}
  
  words <- words[!duplicated(words[c("concept","gender", "language")]),]

  df_small <- merge(small_concepts, words, by="concept", all.x=TRUE)
  df_big <- merge(big_concepts, words, by="concept", all.x=TRUE)
  df <- rbind(df_small, df_big)
  df <- subset(df, !is.na(language))
  
  
  macabre_big_mw <- count_mw(df_big, "macabre.big", name, iter)
  macabre_sm_mw <- count_mw(df_small, "macabre.small", name, iter)
  binder_big_mw <- count_mw(df_big, "binder.et.al.big", name, iter)
  binder_sm_mw <- count_mw(df_small, "binder.et.al.small", name, iter)
  mcrae_big_mw <- count_mw(df_big, "mcrae.et.al.big", name, iter)
  mcrae_sm_mw <- count_mw(df_small, "mcrae.et.al.small", name, iter)
  
  results <- data.frame(
    source=c("macabre.big", "macabre.small", 
             "binder.et.al.big", "binder.et.al.small", 
             "mcrae.et.al.big", "mcrae.et.al.small"),
    pvalue=c(macabre_big_mw, macabre_sm_mw,
             binder_big_mw, binder_sm_mw, 
             mcrae_big_mw, mcrae_sm_mw)
  )
  return(list(df, results))
}
```

```{r}
languages <- list("Archi", "Budukh", "Khinalug", "Kryz", "Lak", "Rutul", "Tsakhur")

path_to_data = "../../data/absolute_size_experiment"

words = read.xlsx(file.path(path_to_data, "annotated_data", "as words.xlsx"))
words = filter(words, is.na(f.compound))

archi <- words[words$language == "Archi",]
nonarchi <- words[words$language != "Archi",]

concepts = read.xlsx(file.path(path_to_data, "annotated_data", "as concepts.xlsx"))
big_concepts = filter(concepts, absolute.size=="big")
small_concepts = filter(concepts, absolute.size=="small")

arhci_joint_df <- data.frame()
archi_mw_results <- data.frame()

nonarhci_joint_df <- data.frame()
nonarchi_mw_results <- data.frame()
for (x in c("A", "B")){
  for (i in c(1000, 5000, 10000)){
  archi_output <- get_data(archi, big_concepts, small_concepts, name=sprintf("archi_%s_%s", x, as.character(i)), i)
#archi_joint_df <- rbind(archi_joint_df, archi_output[[1]])
#archi_mw_results <- rbind(archi_mw_results, archi_output[[2]])

  nonarchi_output <- get_data(nonarchi, big_concepts, small_concepts, name=sprintf("nonarchi_%s_%s", x, as.character(i)), i)
  
  write.xlsx(archi_output[[1]], file.path(path_to_data, "results",  sprintf("%s_%s_as joint archi.xlsx", x, as.character(i))))
    write.xlsx(archi_output[[2]], file.path(path_to_data, "results", sprintf("%s_%s_as results archi.xlsx", x, as.character(i))))
    
    write.xlsx(nonarchi_output[[1]], file.path(path_to_data, "results", sprintf("%s_%s_cs joint non archi.xlsx", x, as.character(i))))
    write.xlsx(nonarchi_output[[2]], file.path(path_to_data, "results", sprintf("%s_%s_cs results non archi.xlsx", x, as.character(i))))
}}
#nonarchi_joint_df <- rbind(nonarchi_joint_df, nonarchi_output[[1]])
#nonarchi_mw_results <- rbind(nonarchi_mw_results, nonarchi_output[[2]])

```
